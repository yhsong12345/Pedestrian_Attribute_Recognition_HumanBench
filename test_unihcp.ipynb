{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:34.519874Z",
     "start_time": "2025-03-06T05:36:31.884179Z"
    }
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "\n",
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "def to_MB(a):\n",
    "    return a/1024.0/1024.0"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:35.046795Z",
     "start_time": "2025-03-06T05:36:35.043784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pickle_path = '/purestorage/AILAB/AI_2/youhans/workspace/reid/person/HumanBench/PA100k/dataset_all.pkl'\n",
    "# root_path = \"/purestorage/AILAB/AI_2/datasets/ReID/PA-100k/data/release_data/PA-100k/\"\n",
    "yaml_path = '/purestorage/AILAB/AI_2/youhans/workspace/reid/person/HumanBench/UniHCP/experiments/unihcp/release/peta_vitbase_coslr1e3_104k_b4324g88_h256_I2k_1_10_001_2I_fairscale_m256.yaml'\n",
    "root = '/purestorage/AILAB/AI_2/youhans/workspace/reid/person/HumanBench/UniHCP/checkpoints'\n",
    "checkpoint_path = 'peta_vitbase_modi/peta_vitbase_modi.pth'\n",
    "zeroshot = False\n",
    "checkpoint = os.path.join(root, checkpoint_path)\n",
    "datatype = 'peta'    ###'PA-100k'"
   ],
   "id": "22fecb0bb39bf890",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:38.787777Z",
     "start_time": "2025-03-06T05:36:35.165695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import core.models.backbones as backbones\n",
    "import core.models.necks as necks\n",
    "import core.models.decoders as decoders\n",
    "from core.models.model_entry import model_entry\n",
    "\n",
    "\n",
    "\n",
    "data = yaml.load(open(yaml_path, 'r'), Loader=yaml.SafeLoader)\n",
    "# print(data)\n",
    "pickle_path = data['tasks'][0]['dataset']['kwargs']['task_spec']['data_path']\n",
    "root_path = data['tasks'][0]['dataset']['kwargs']['task_spec']['root_path']\n",
    "height = data['tasks'][0]['dataset']['kwargs']['augmentation']['height']\n",
    "width = data['tasks'][0]['dataset']['kwargs']['augmentation']['width']\n",
    "backbone_structure = data['tasks'][0]['backbone']\n",
    "\n",
    "\n",
    "backbone_module = backbones.backbone_entry(backbone_structure)\n",
    "neck_structure = data['common']['neck']\n",
    "neck_structure['kwargs']['backbone'] = backbone_module\n",
    "neck_module = necks.neck_entry(neck_structure)\n",
    "\n",
    "\n",
    "data['tasks'][0]['decoder']['kwargs']['ignore_value'] = None\n",
    "data['tasks'][0]['decoder']['kwargs']['num_classes'] = 0\n",
    "decoder_structure = data['tasks'][0]['decoder']\n",
    "decoder_structure['kwargs']['backbone'] = backbone_module\n",
    "decoder_structure['kwargs']['neck'] = neck_module\n",
    "decoder_structure['kwargs']['ginfo'] = None\n",
    "decoder_structure['kwargs']['bn_group'] = 1\n",
    "# decoder_structure['kwargs']['loss_cfg']['kwargs'] = None\n",
    "# print(decoder_structure['kwargs']['loss_cfg'])\n",
    "decoder_module = decoders.decoder_entry(decoder_structure)\n",
    "# print(decoder_module)"
   ],
   "id": "c2e062715b6bb942",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/purestorage/AILAB/AI_2/youhans/miniconda3/envs/humanbench/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no mc\n",
      "ceph can not be used\n",
      "no mc\n",
      "no mc\n",
      "ceph can not be used\n",
      "[rank 0] Position interpolate from (14, 14) to (84, 84)\n",
      "Missing keys: []\n",
      "\n",
      "finish load\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:38.900619Z",
     "start_time": "2025-03-06T05:36:38.892430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pickle_file = pickle.load(open(pickle_path, 'rb'))\n",
    "print(pickle_file.keys())\n",
    "\n",
    "image_names = pickle_file['image_name']\n",
    "labels = pickle_file['label']\n",
    "id = pickle_file['attr_name']\n",
    "# order = pickle_file['label_idx']['eval']\n",
    "# id = [id[i] for i in order]"
   ],
   "id": "5fb9bd84f540edc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['description', 'reorder', 'root', 'label_idx', 'partition', 'weight_train', 'weight_trainval', 'image_name', 'label', 'attr_name'])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:38.926535Z",
     "start_time": "2025-03-06T05:36:38.923065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(img, height, width):\n",
    "    img = cv2.resize(img, (height, width))\n",
    "    img = img / 255.0\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img).float()\n",
    "    img = img.unsqueeze(0)\n",
    "    return img\n",
    "\n"
   ],
   "id": "b76bbc847b6e765b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:40.118337Z",
     "start_time": "2025-03-06T05:36:38.967547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model_entry(backbone_module, neck_module, decoder_module)\n",
    "checkpoint = torch.load(checkpoint, map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=False)"
   ],
   "id": "b87dc1a83267e958",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rank 0] add param pos_embed as backbone_specific\n",
      "[rank 0] add param patch_embed.proj.weight as backbone_specific\n",
      "[rank 0] add param patch_embed.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.0.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.0.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.1.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.1.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.2.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.2.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.3.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.3.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.4.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.4.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.5.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.5.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.6.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.6.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.7.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.7.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.8.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.8.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.9.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.9.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.10.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.10.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.norm1.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.norm1.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.attn.qkv.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.attn.qkv.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.attn.proj.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.attn.proj.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.norm2.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.norm2.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.mlp.fc1.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.mlp.fc1.bias as backbone_specific\n",
      "[rank 0] add param blocks.11.mlp.fc2.weight as backbone_specific\n",
      "[rank 0] add param blocks.11.mlp.fc2.bias as backbone_specific\n",
      "[rank 0] add param norm.weight as backbone_specific\n",
      "[rank 0] add param norm.bias as backbone_specific\n",
      "[rank 0] add param mask_map.0.weight as neck_specific\n",
      "[rank 0] add param mask_map.0.bias as neck_specific\n",
      "[rank 0] add param mask_map.1.weight as neck_specific\n",
      "[rank 0] add param mask_map.1.bias as neck_specific\n",
      "[rank 0] add param mask_map.3.weight as neck_specific\n",
      "[rank 0] add param mask_map.3.bias as neck_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.0.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.1.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.2.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.3.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.4.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.5.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.6.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.7.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_self_attention_layers.8.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.0.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.1.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.2.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.3.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.4.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.5.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.6.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.7.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_cross_attention_layers.8.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.0.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.1.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.2.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.3.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.4.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.5.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.6.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.7.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.linear1.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.linear1.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.linear2.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.linear2.bias as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.transformer_ffn_layers.8.norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.decoder_norm.weight as decoder_specific\n",
      "[rank 0] add param predictor.decoder_norm.bias as decoder_specific\n",
      "[rank 0] add param predictor.query_feat.weight as decoder_specific\n",
      "[rank 0] add param predictor.query_embed.weight as decoder_specific\n",
      "[rank 0] add param predictor.level_embed.weight as decoder_specific\n",
      "[rank 0] add param predictor.input_proj.0.weight as decoder_specific\n",
      "[rank 0] add param predictor.input_proj.0.bias as decoder_specific\n",
      "[rank 0] add param predictor.class_embed.weight as decoder_specific\n",
      "[rank 0] add param predictor.class_embed.bias as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.0.weight as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.0.bias as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.1.weight as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.1.bias as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.2.weight as decoder_specific\n",
      "[rank 0] add param predictor.mask_embed.layers.2.bias as decoder_specific\n",
      "[rank 0] add param predictor.adapt_pos2d.0.weight as decoder_specific\n",
      "[rank 0] add param predictor.adapt_pos2d.0.bias as decoder_specific\n",
      "[rank 0] add param predictor.adapt_pos2d.2.weight as decoder_specific\n",
      "[rank 0] add param predictor.adapt_pos2d.2.bias as decoder_specific\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['backbone_module.pos_embed', 'backbone_module.patch_embed.proj.weight', 'backbone_module.patch_embed.proj.bias', 'backbone_module.blocks.0.norm1.weight', 'backbone_module.blocks.0.norm1.bias', 'backbone_module.blocks.0.attn.qkv.weight', 'backbone_module.blocks.0.attn.qkv.bias', 'backbone_module.blocks.0.attn.proj.weight', 'backbone_module.blocks.0.attn.proj.bias', 'backbone_module.blocks.0.norm2.weight', 'backbone_module.blocks.0.norm2.bias', 'backbone_module.blocks.0.mlp.fc1.weight', 'backbone_module.blocks.0.mlp.fc1.bias', 'backbone_module.blocks.0.mlp.fc2.weight', 'backbone_module.blocks.0.mlp.fc2.bias', 'backbone_module.blocks.1.norm1.weight', 'backbone_module.blocks.1.norm1.bias', 'backbone_module.blocks.1.attn.qkv.weight', 'backbone_module.blocks.1.attn.qkv.bias', 'backbone_module.blocks.1.attn.proj.weight', 'backbone_module.blocks.1.attn.proj.bias', 'backbone_module.blocks.1.norm2.weight', 'backbone_module.blocks.1.norm2.bias', 'backbone_module.blocks.1.mlp.fc1.weight', 'backbone_module.blocks.1.mlp.fc1.bias', 'backbone_module.blocks.1.mlp.fc2.weight', 'backbone_module.blocks.1.mlp.fc2.bias', 'backbone_module.blocks.2.norm1.weight', 'backbone_module.blocks.2.norm1.bias', 'backbone_module.blocks.2.attn.qkv.weight', 'backbone_module.blocks.2.attn.qkv.bias', 'backbone_module.blocks.2.attn.proj.weight', 'backbone_module.blocks.2.attn.proj.bias', 'backbone_module.blocks.2.norm2.weight', 'backbone_module.blocks.2.norm2.bias', 'backbone_module.blocks.2.mlp.fc1.weight', 'backbone_module.blocks.2.mlp.fc1.bias', 'backbone_module.blocks.2.mlp.fc2.weight', 'backbone_module.blocks.2.mlp.fc2.bias', 'backbone_module.blocks.3.norm1.weight', 'backbone_module.blocks.3.norm1.bias', 'backbone_module.blocks.3.attn.qkv.weight', 'backbone_module.blocks.3.attn.qkv.bias', 'backbone_module.blocks.3.attn.proj.weight', 'backbone_module.blocks.3.attn.proj.bias', 'backbone_module.blocks.3.norm2.weight', 'backbone_module.blocks.3.norm2.bias', 'backbone_module.blocks.3.mlp.fc1.weight', 'backbone_module.blocks.3.mlp.fc1.bias', 'backbone_module.blocks.3.mlp.fc2.weight', 'backbone_module.blocks.3.mlp.fc2.bias', 'backbone_module.blocks.4.norm1.weight', 'backbone_module.blocks.4.norm1.bias', 'backbone_module.blocks.4.attn.qkv.weight', 'backbone_module.blocks.4.attn.qkv.bias', 'backbone_module.blocks.4.attn.proj.weight', 'backbone_module.blocks.4.attn.proj.bias', 'backbone_module.blocks.4.norm2.weight', 'backbone_module.blocks.4.norm2.bias', 'backbone_module.blocks.4.mlp.fc1.weight', 'backbone_module.blocks.4.mlp.fc1.bias', 'backbone_module.blocks.4.mlp.fc2.weight', 'backbone_module.blocks.4.mlp.fc2.bias', 'backbone_module.blocks.5.norm1.weight', 'backbone_module.blocks.5.norm1.bias', 'backbone_module.blocks.5.attn.qkv.weight', 'backbone_module.blocks.5.attn.qkv.bias', 'backbone_module.blocks.5.attn.proj.weight', 'backbone_module.blocks.5.attn.proj.bias', 'backbone_module.blocks.5.norm2.weight', 'backbone_module.blocks.5.norm2.bias', 'backbone_module.blocks.5.mlp.fc1.weight', 'backbone_module.blocks.5.mlp.fc1.bias', 'backbone_module.blocks.5.mlp.fc2.weight', 'backbone_module.blocks.5.mlp.fc2.bias', 'backbone_module.blocks.6.norm1.weight', 'backbone_module.blocks.6.norm1.bias', 'backbone_module.blocks.6.attn.qkv.weight', 'backbone_module.blocks.6.attn.qkv.bias', 'backbone_module.blocks.6.attn.proj.weight', 'backbone_module.blocks.6.attn.proj.bias', 'backbone_module.blocks.6.norm2.weight', 'backbone_module.blocks.6.norm2.bias', 'backbone_module.blocks.6.mlp.fc1.weight', 'backbone_module.blocks.6.mlp.fc1.bias', 'backbone_module.blocks.6.mlp.fc2.weight', 'backbone_module.blocks.6.mlp.fc2.bias', 'backbone_module.blocks.7.norm1.weight', 'backbone_module.blocks.7.norm1.bias', 'backbone_module.blocks.7.attn.qkv.weight', 'backbone_module.blocks.7.attn.qkv.bias', 'backbone_module.blocks.7.attn.proj.weight', 'backbone_module.blocks.7.attn.proj.bias', 'backbone_module.blocks.7.norm2.weight', 'backbone_module.blocks.7.norm2.bias', 'backbone_module.blocks.7.mlp.fc1.weight', 'backbone_module.blocks.7.mlp.fc1.bias', 'backbone_module.blocks.7.mlp.fc2.weight', 'backbone_module.blocks.7.mlp.fc2.bias', 'backbone_module.blocks.8.norm1.weight', 'backbone_module.blocks.8.norm1.bias', 'backbone_module.blocks.8.attn.qkv.weight', 'backbone_module.blocks.8.attn.qkv.bias', 'backbone_module.blocks.8.attn.proj.weight', 'backbone_module.blocks.8.attn.proj.bias', 'backbone_module.blocks.8.norm2.weight', 'backbone_module.blocks.8.norm2.bias', 'backbone_module.blocks.8.mlp.fc1.weight', 'backbone_module.blocks.8.mlp.fc1.bias', 'backbone_module.blocks.8.mlp.fc2.weight', 'backbone_module.blocks.8.mlp.fc2.bias', 'backbone_module.blocks.9.norm1.weight', 'backbone_module.blocks.9.norm1.bias', 'backbone_module.blocks.9.attn.qkv.weight', 'backbone_module.blocks.9.attn.qkv.bias', 'backbone_module.blocks.9.attn.proj.weight', 'backbone_module.blocks.9.attn.proj.bias', 'backbone_module.blocks.9.norm2.weight', 'backbone_module.blocks.9.norm2.bias', 'backbone_module.blocks.9.mlp.fc1.weight', 'backbone_module.blocks.9.mlp.fc1.bias', 'backbone_module.blocks.9.mlp.fc2.weight', 'backbone_module.blocks.9.mlp.fc2.bias', 'backbone_module.blocks.10.norm1.weight', 'backbone_module.blocks.10.norm1.bias', 'backbone_module.blocks.10.attn.qkv.weight', 'backbone_module.blocks.10.attn.qkv.bias', 'backbone_module.blocks.10.attn.proj.weight', 'backbone_module.blocks.10.attn.proj.bias', 'backbone_module.blocks.10.norm2.weight', 'backbone_module.blocks.10.norm2.bias', 'backbone_module.blocks.10.mlp.fc1.weight', 'backbone_module.blocks.10.mlp.fc1.bias', 'backbone_module.blocks.10.mlp.fc2.weight', 'backbone_module.blocks.10.mlp.fc2.bias', 'backbone_module.blocks.11.norm1.weight', 'backbone_module.blocks.11.norm1.bias', 'backbone_module.blocks.11.attn.qkv.weight', 'backbone_module.blocks.11.attn.qkv.bias', 'backbone_module.blocks.11.attn.proj.weight', 'backbone_module.blocks.11.attn.proj.bias', 'backbone_module.blocks.11.norm2.weight', 'backbone_module.blocks.11.norm2.bias', 'backbone_module.blocks.11.mlp.fc1.weight', 'backbone_module.blocks.11.mlp.fc1.bias', 'backbone_module.blocks.11.mlp.fc2.weight', 'backbone_module.blocks.11.mlp.fc2.bias', 'backbone_module.norm.weight', 'backbone_module.norm.bias', 'neck_module.mask_map.0.weight', 'neck_module.mask_map.0.bias', 'neck_module.mask_map.1.weight', 'neck_module.mask_map.1.bias', 'neck_module.mask_map.1.ln.weight', 'neck_module.mask_map.1.ln.bias', 'neck_module.mask_map.3.weight', 'neck_module.mask_map.3.bias', 'decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.0.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.0.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.1.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.1.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.2.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.2.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.3.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.3.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.4.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.4.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.5.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.5.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.6.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.6.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.7.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.7.norm.bias', 'decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight', 'decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias', 'decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight', 'decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias', 'decoder_module.predictor.transformer_self_attention_layers.8.norm.weight', 'decoder_module.predictor.transformer_self_attention_layers.8.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.0.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.0.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.1.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.1.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.2.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.2.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.3.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.3.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.4.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.4.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.5.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.5.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.6.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.6.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.7.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.7.norm.bias', 'decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight', 'decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias', 'decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight', 'decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias', 'decoder_module.predictor.transformer_cross_attention_layers.8.norm.weight', 'decoder_module.predictor.transformer_cross_attention_layers.8.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.0.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.0.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.0.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.0.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.0.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.0.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.1.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.1.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.1.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.1.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.1.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.1.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.2.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.2.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.2.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.2.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.2.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.2.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.3.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.3.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.3.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.3.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.3.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.3.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.4.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.4.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.4.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.4.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.4.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.4.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.5.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.5.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.5.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.5.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.5.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.5.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.6.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.6.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.6.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.6.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.6.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.6.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.7.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.7.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.7.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.7.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.7.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.7.norm.bias', 'decoder_module.predictor.transformer_ffn_layers.8.linear1.weight', 'decoder_module.predictor.transformer_ffn_layers.8.linear1.bias', 'decoder_module.predictor.transformer_ffn_layers.8.linear2.weight', 'decoder_module.predictor.transformer_ffn_layers.8.linear2.bias', 'decoder_module.predictor.transformer_ffn_layers.8.norm.weight', 'decoder_module.predictor.transformer_ffn_layers.8.norm.bias', 'decoder_module.predictor.decoder_norm.weight', 'decoder_module.predictor.decoder_norm.bias', 'decoder_module.predictor.query_feat.weight', 'decoder_module.predictor.query_embed.weight', 'decoder_module.predictor.level_embed.weight', 'decoder_module.predictor.input_proj.0.weight', 'decoder_module.predictor.input_proj.0.bias', 'decoder_module.predictor.class_embed.weight', 'decoder_module.predictor.class_embed.bias', 'decoder_module.predictor.mask_embed.layers.0.weight', 'decoder_module.predictor.mask_embed.layers.0.bias', 'decoder_module.predictor.mask_embed.layers.1.weight', 'decoder_module.predictor.mask_embed.layers.1.bias', 'decoder_module.predictor.mask_embed.layers.2.weight', 'decoder_module.predictor.mask_embed.layers.2.bias', 'decoder_module.predictor.adapt_pos2d.0.weight', 'decoder_module.predictor.adapt_pos2d.0.bias', 'decoder_module.predictor.adapt_pos2d.2.weight', 'decoder_module.predictor.adapt_pos2d.2.bias'], unexpected_keys=['module.backbone_module.pos_embed', 'module.backbone_module.patch_embed.proj.weight', 'module.backbone_module.patch_embed.proj.bias', 'module.backbone_module.blocks.0.norm1.weight', 'module.backbone_module.blocks.0.norm1.bias', 'module.backbone_module.blocks.0.attn.qkv.weight', 'module.backbone_module.blocks.0.attn.qkv.bias', 'module.backbone_module.blocks.0.attn.proj.weight', 'module.backbone_module.blocks.0.attn.proj.bias', 'module.backbone_module.blocks.0.norm2.weight', 'module.backbone_module.blocks.0.norm2.bias', 'module.backbone_module.blocks.0.mlp.fc1.weight', 'module.backbone_module.blocks.0.mlp.fc1.bias', 'module.backbone_module.blocks.0.mlp.fc2.weight', 'module.backbone_module.blocks.0.mlp.fc2.bias', 'module.backbone_module.blocks.1.norm1.weight', 'module.backbone_module.blocks.1.norm1.bias', 'module.backbone_module.blocks.1.attn.qkv.weight', 'module.backbone_module.blocks.1.attn.qkv.bias', 'module.backbone_module.blocks.1.attn.proj.weight', 'module.backbone_module.blocks.1.attn.proj.bias', 'module.backbone_module.blocks.1.norm2.weight', 'module.backbone_module.blocks.1.norm2.bias', 'module.backbone_module.blocks.1.mlp.fc1.weight', 'module.backbone_module.blocks.1.mlp.fc1.bias', 'module.backbone_module.blocks.1.mlp.fc2.weight', 'module.backbone_module.blocks.1.mlp.fc2.bias', 'module.backbone_module.blocks.2.norm1.weight', 'module.backbone_module.blocks.2.norm1.bias', 'module.backbone_module.blocks.2.attn.qkv.weight', 'module.backbone_module.blocks.2.attn.qkv.bias', 'module.backbone_module.blocks.2.attn.proj.weight', 'module.backbone_module.blocks.2.attn.proj.bias', 'module.backbone_module.blocks.2.norm2.weight', 'module.backbone_module.blocks.2.norm2.bias', 'module.backbone_module.blocks.2.mlp.fc1.weight', 'module.backbone_module.blocks.2.mlp.fc1.bias', 'module.backbone_module.blocks.2.mlp.fc2.weight', 'module.backbone_module.blocks.2.mlp.fc2.bias', 'module.backbone_module.blocks.3.norm1.weight', 'module.backbone_module.blocks.3.norm1.bias', 'module.backbone_module.blocks.3.attn.qkv.weight', 'module.backbone_module.blocks.3.attn.qkv.bias', 'module.backbone_module.blocks.3.attn.proj.weight', 'module.backbone_module.blocks.3.attn.proj.bias', 'module.backbone_module.blocks.3.norm2.weight', 'module.backbone_module.blocks.3.norm2.bias', 'module.backbone_module.blocks.3.mlp.fc1.weight', 'module.backbone_module.blocks.3.mlp.fc1.bias', 'module.backbone_module.blocks.3.mlp.fc2.weight', 'module.backbone_module.blocks.3.mlp.fc2.bias', 'module.backbone_module.blocks.4.norm1.weight', 'module.backbone_module.blocks.4.norm1.bias', 'module.backbone_module.blocks.4.attn.qkv.weight', 'module.backbone_module.blocks.4.attn.qkv.bias', 'module.backbone_module.blocks.4.attn.proj.weight', 'module.backbone_module.blocks.4.attn.proj.bias', 'module.backbone_module.blocks.4.norm2.weight', 'module.backbone_module.blocks.4.norm2.bias', 'module.backbone_module.blocks.4.mlp.fc1.weight', 'module.backbone_module.blocks.4.mlp.fc1.bias', 'module.backbone_module.blocks.4.mlp.fc2.weight', 'module.backbone_module.blocks.4.mlp.fc2.bias', 'module.backbone_module.blocks.5.norm1.weight', 'module.backbone_module.blocks.5.norm1.bias', 'module.backbone_module.blocks.5.attn.qkv.weight', 'module.backbone_module.blocks.5.attn.qkv.bias', 'module.backbone_module.blocks.5.attn.proj.weight', 'module.backbone_module.blocks.5.attn.proj.bias', 'module.backbone_module.blocks.5.norm2.weight', 'module.backbone_module.blocks.5.norm2.bias', 'module.backbone_module.blocks.5.mlp.fc1.weight', 'module.backbone_module.blocks.5.mlp.fc1.bias', 'module.backbone_module.blocks.5.mlp.fc2.weight', 'module.backbone_module.blocks.5.mlp.fc2.bias', 'module.backbone_module.blocks.6.norm1.weight', 'module.backbone_module.blocks.6.norm1.bias', 'module.backbone_module.blocks.6.attn.qkv.weight', 'module.backbone_module.blocks.6.attn.qkv.bias', 'module.backbone_module.blocks.6.attn.proj.weight', 'module.backbone_module.blocks.6.attn.proj.bias', 'module.backbone_module.blocks.6.norm2.weight', 'module.backbone_module.blocks.6.norm2.bias', 'module.backbone_module.blocks.6.mlp.fc1.weight', 'module.backbone_module.blocks.6.mlp.fc1.bias', 'module.backbone_module.blocks.6.mlp.fc2.weight', 'module.backbone_module.blocks.6.mlp.fc2.bias', 'module.backbone_module.blocks.7.norm1.weight', 'module.backbone_module.blocks.7.norm1.bias', 'module.backbone_module.blocks.7.attn.qkv.weight', 'module.backbone_module.blocks.7.attn.qkv.bias', 'module.backbone_module.blocks.7.attn.proj.weight', 'module.backbone_module.blocks.7.attn.proj.bias', 'module.backbone_module.blocks.7.norm2.weight', 'module.backbone_module.blocks.7.norm2.bias', 'module.backbone_module.blocks.7.mlp.fc1.weight', 'module.backbone_module.blocks.7.mlp.fc1.bias', 'module.backbone_module.blocks.7.mlp.fc2.weight', 'module.backbone_module.blocks.7.mlp.fc2.bias', 'module.backbone_module.blocks.8.norm1.weight', 'module.backbone_module.blocks.8.norm1.bias', 'module.backbone_module.blocks.8.attn.qkv.weight', 'module.backbone_module.blocks.8.attn.qkv.bias', 'module.backbone_module.blocks.8.attn.proj.weight', 'module.backbone_module.blocks.8.attn.proj.bias', 'module.backbone_module.blocks.8.norm2.weight', 'module.backbone_module.blocks.8.norm2.bias', 'module.backbone_module.blocks.8.mlp.fc1.weight', 'module.backbone_module.blocks.8.mlp.fc1.bias', 'module.backbone_module.blocks.8.mlp.fc2.weight', 'module.backbone_module.blocks.8.mlp.fc2.bias', 'module.backbone_module.blocks.9.norm1.weight', 'module.backbone_module.blocks.9.norm1.bias', 'module.backbone_module.blocks.9.attn.qkv.weight', 'module.backbone_module.blocks.9.attn.qkv.bias', 'module.backbone_module.blocks.9.attn.proj.weight', 'module.backbone_module.blocks.9.attn.proj.bias', 'module.backbone_module.blocks.9.norm2.weight', 'module.backbone_module.blocks.9.norm2.bias', 'module.backbone_module.blocks.9.mlp.fc1.weight', 'module.backbone_module.blocks.9.mlp.fc1.bias', 'module.backbone_module.blocks.9.mlp.fc2.weight', 'module.backbone_module.blocks.9.mlp.fc2.bias', 'module.backbone_module.blocks.10.norm1.weight', 'module.backbone_module.blocks.10.norm1.bias', 'module.backbone_module.blocks.10.attn.qkv.weight', 'module.backbone_module.blocks.10.attn.qkv.bias', 'module.backbone_module.blocks.10.attn.proj.weight', 'module.backbone_module.blocks.10.attn.proj.bias', 'module.backbone_module.blocks.10.norm2.weight', 'module.backbone_module.blocks.10.norm2.bias', 'module.backbone_module.blocks.10.mlp.fc1.weight', 'module.backbone_module.blocks.10.mlp.fc1.bias', 'module.backbone_module.blocks.10.mlp.fc2.weight', 'module.backbone_module.blocks.10.mlp.fc2.bias', 'module.backbone_module.blocks.11.norm1.weight', 'module.backbone_module.blocks.11.norm1.bias', 'module.backbone_module.blocks.11.attn.qkv.weight', 'module.backbone_module.blocks.11.attn.qkv.bias', 'module.backbone_module.blocks.11.attn.proj.weight', 'module.backbone_module.blocks.11.attn.proj.bias', 'module.backbone_module.blocks.11.norm2.weight', 'module.backbone_module.blocks.11.norm2.bias', 'module.backbone_module.blocks.11.mlp.fc1.weight', 'module.backbone_module.blocks.11.mlp.fc1.bias', 'module.backbone_module.blocks.11.mlp.fc2.weight', 'module.backbone_module.blocks.11.mlp.fc2.bias', 'module.backbone_module.norm.weight', 'module.backbone_module.norm.bias', 'module.neck_module.mask_map.0.weight', 'module.neck_module.mask_map.0.bias', 'module.neck_module.mask_map.1.weight', 'module.neck_module.mask_map.1.bias', 'module.neck_module.mask_map.1.ln.weight', 'module.neck_module.mask_map.1.ln.bias', 'module.neck_module.mask_map.3.weight', 'module.neck_module.mask_map.3.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.0.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.0.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.0.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.1.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.1.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.1.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.2.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.2.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.2.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.3.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.3.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.3.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.4.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.4.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.4.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.5.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.5.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.5.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.6.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.6.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.6.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.7.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.7.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.7.norm.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.8.self_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_self_attention_layers.8.norm.weight', 'module.decoder_module.predictor.transformer_self_attention_layers.8.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.0.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.1.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.2.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.3.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.4.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.5.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.6.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.7.norm.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.in_proj_bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.multihead_attn.out_proj.bias', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.norm.weight', 'module.decoder_module.predictor.transformer_cross_attention_layers.8.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.0.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.0.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.0.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.0.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.0.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.0.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.1.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.1.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.1.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.1.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.1.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.1.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.2.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.2.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.2.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.2.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.2.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.2.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.3.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.3.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.3.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.3.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.3.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.3.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.4.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.4.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.4.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.4.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.4.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.4.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.5.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.5.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.5.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.5.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.5.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.5.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.6.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.6.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.6.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.6.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.6.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.6.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.7.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.7.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.7.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.7.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.7.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.7.norm.bias', 'module.decoder_module.predictor.transformer_ffn_layers.8.linear1.weight', 'module.decoder_module.predictor.transformer_ffn_layers.8.linear1.bias', 'module.decoder_module.predictor.transformer_ffn_layers.8.linear2.weight', 'module.decoder_module.predictor.transformer_ffn_layers.8.linear2.bias', 'module.decoder_module.predictor.transformer_ffn_layers.8.norm.weight', 'module.decoder_module.predictor.transformer_ffn_layers.8.norm.bias', 'module.decoder_module.predictor.decoder_norm.weight', 'module.decoder_module.predictor.decoder_norm.bias', 'module.decoder_module.predictor.query_feat.weight', 'module.decoder_module.predictor.query_embed.weight', 'module.decoder_module.predictor.level_embed.weight', 'module.decoder_module.predictor.input_proj.0.weight', 'module.decoder_module.predictor.input_proj.0.bias', 'module.decoder_module.predictor.class_embed.weight', 'module.decoder_module.predictor.class_embed.bias', 'module.decoder_module.predictor.mask_embed.layers.0.weight', 'module.decoder_module.predictor.mask_embed.layers.0.bias', 'module.decoder_module.predictor.mask_embed.layers.1.weight', 'module.decoder_module.predictor.mask_embed.layers.1.bias', 'module.decoder_module.predictor.mask_embed.layers.2.weight', 'module.decoder_module.predictor.mask_embed.layers.2.bias', 'module.decoder_module.predictor.adapt_pos2d.0.weight', 'module.decoder_module.predictor.adapt_pos2d.0.bias', 'module.decoder_module.predictor.adapt_pos2d.2.weight', 'module.decoder_module.predictor.adapt_pos2d.2.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:40.496771Z",
     "start_time": "2025-03-06T05:36:40.409814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ],
   "id": "4ab946fab4dfd1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_entry(\n",
       "  (backbone_module): ViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.0181818176060915)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.036363635212183)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.05454545468091965)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.072727270424366)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.09090908616781235)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.10909091681241989)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.12727272510528564)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1454545557498932)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.16363637149333954)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.1818181872367859)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (drop_path): DropPath(p=0.20000000298023224)\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_pre): Identity()\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (neck_module): SimpleNeck(\n",
       "    (mask_map): Sequential(\n",
       "      (0): ConvTranspose2d(768, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): Norm2d(\n",
       "        (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (decoder_module): AIOHead(\n",
       "    (predictor): TransformerDecoder(\n",
       "      (pe_layer): Positional encoding PositionEmbeddingSine\n",
       "          num_pos_feats: 128\n",
       "          temperature: 10000\n",
       "          normalize: True\n",
       "          scale: 6.283185307179586\n",
       "      (transformer_self_attention_layers): ModuleList(\n",
       "        (0-8): 9 x SelfAttentionLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (transformer_cross_attention_layers): ModuleList(\n",
       "        (0-8): 9 x CrossAttentionLayer(\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (transformer_ffn_layers): ModuleList(\n",
       "        (0-8): 9 x FFNLayer(\n",
       "          (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (decoder_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (query_feat): Embedding(105, 256)\n",
       "      (query_embed): Embedding(105, 256)\n",
       "      (level_embed): Embedding(1, 256)\n",
       "      (input_proj): ModuleList(\n",
       "        (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (class_embed): Linear(in_features=256, out_features=1, bias=True)\n",
       "      (mask_embed): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (adapt_pos2d): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (loss): CEL_Sigmoid(sample_weight=None, size_average=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:47:39.608442Z",
     "start_time": "2025-03-06T05:47:39.481338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from matplotlib.pyplot import imshow, show\n",
    "# img_dir = \"/purestorage/AILAB/AI_2/youhans/workspace/reid/person/HumanBench\" + \"/test/\"\n",
    "# img_name = \"pedestrian7\" + '.jpg'\n",
    "# img_path = os.path.join(img_dir, img_name)\n",
    "# img_path = \"/purestorage/AILAB/AI_2/datasets/ReID/PA-100k/data/release_data/PA-100k/000013.jpg\"\n",
    "img_path = \"/purestorage/AILAB/AI_2/datasets/ReID/PETA/PETA_dataset/CAVIAR4REID/archive/0003_002.jpg\"\n",
    "print(img_path)\n",
    "img = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "imshow(img_rgb)\n",
    "show()\n",
    "\n",
    "img = preprocess(img, height, width)\n",
    "img = img.to(device)\n",
    "print(img.shape)\n",
    "batch = {'image': img, 'label': None}"
   ],
   "id": "656efc949fac6799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/purestorage/AILAB/AI_2/datasets/ReID/PETA/PETA_dataset/CAVIAR4REID/archive/0003_002.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 192, 256])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:47:39.900742Z",
     "start_time": "2025-03-06T05:47:39.789238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "starter.record()\n",
    "for _ in range(3):\n",
    "    results = model(batch, 0)\n",
    "ender.record()\n",
    "print(f\"After model to device: {to_MB(torch.cuda.memory_allocated()):.2f}MB\")\n",
    "torch.cuda.synchronize()\n",
    "curr_time = starter.elapsed_time(ender) ##\n",
    "print(f'{curr_time:.2f}ms')"
   ],
   "id": "4ea63d4dbacc83b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After model to device: 1339.32MB\n",
      "105.37ms\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:47:40.106421Z",
     "start_time": "2025-03-06T05:47:40.068920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "probs = torch.sigmoid(results['logit']).cpu().data.numpy()\n",
    "probs = probs.tolist()\n",
    "if datatype == 'PA-100k':\n",
    "    for i, prob in enumerate(probs):\n",
    "        print(id[i], prob)\n",
    "elif datatype == 'peta':\n",
    "    from easydict import EasyDict\n",
    "    if zeroshot:\n",
    "\n",
    "        gender = [16, 87]  # stay 2\n",
    "        age = [0,1,2,3,80] # stay 4\n",
    "        lowerlong = [6,8,12,31,84,94,95,102] # modified 1\n",
    "        lowershort = [25,90] # modified 1\n",
    "        lowershortskirt = [27] # stay 1\n",
    "        lowerlongskirt = [92] # stay 1\n",
    "        upperlongsleeve = [7,9,11,21,29,93,100,103,104] # modified 1\n",
    "        uppershortsleeve = [26,32] # modified 1\n",
    "        uppernosleeve = [97] # stay 1\n",
    "        hair = [15, 82, 98] # stay 3\n",
    "        lowercolor = list(range(46, 57)) # stay\n",
    "        uppercolor = list(range(35, 46)) # stay\n",
    "        haircolor = list(range(57, 68)) # stay\n",
    "\n",
    "        value_list = gender + age + lowerlong + lowershort + lowershortskirt + lowerlongskirt + upperlongsleeve + \\\n",
    "            uppershortsleeve + uppernosleeve + hair + lowercolor + uppercolor + haircolor\n",
    "\n",
    "        lowerbody = lowerlong + lowershort + lowershortskirt + lowerlongskirt\n",
    "        upperbody = upperlongsleeve + uppershortsleeve + uppernosleeve\n",
    "\n",
    "        answers_idx = EasyDict()\n",
    "\n",
    "        attr_list = [str(w) for w in id]\n",
    "\n",
    "        answers_idx[\"gender\"] = []\n",
    "        answers_idx[\"age\"] = []\n",
    "        # answers_idx[\"lowerbodylong\"] = []\n",
    "        # answers_idx[\"lowerbodyshort\"] = []\n",
    "        # answers_idx[\"lowerbodyshortskirt\"] = []\n",
    "        # answers_idx[\"lowerbodylongskirt\"] = []\n",
    "        # answers_idx[\"upperbodylongsleeve\"] = []\n",
    "        # answers_idx[\"upperbodyshortsleeve\"] = []\n",
    "        # answers_idx[\"upperbodynosleeve\"] = []\n",
    "        answers_idx[\"lowerbody\"] = []\n",
    "        answers_idx[\"upperbody\"] = []\n",
    "        answers_idx[\"hair\"] = []\n",
    "        answers_idx[\"lowercolor\"] = []\n",
    "        answers_idx[\"uppercolor\"] = []\n",
    "        answers_idx[\"haircolor\"] = []\n",
    "\n",
    "\n",
    "        for a, b in zip(value_list, probs):\n",
    "            list_idx = {}\n",
    "            if a in gender:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"gender\"].append(list_idx)\n",
    "            elif a in age:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"age\"].append(list_idx)\n",
    "\n",
    "            elif a in lowerbody:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"lowerbody\"].append(list_idx)\n",
    "\n",
    "            elif a in upperbody:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"upperbody\"].append(list_idx)\n",
    "            # elif a in lowerlong:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodylong\"].append(list_idx)\n",
    "            # elif a in lowershort:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodyshort\"].append(list_idx)\n",
    "            # elif a in lowershortskirt:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodyshortskirt\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in lowerlongskirt:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodylongskirt\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in upperlongsleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodylongsleeve\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in uppershortsleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodyshortsleeve\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in uppernosleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodynosleeve\"].append(list_idx)\n",
    "\n",
    "            elif a in hair:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"hair\"].append(list_idx)\n",
    "\n",
    "            elif a in lowercolor:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"lowercolor\"].append(list_idx)\n",
    "\n",
    "            elif a in uppercolor:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"uppercolor\"].append(list_idx)\n",
    "\n",
    "            elif a in haircolor:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"haircolor\"].append(list_idx)\n",
    "\n",
    "\n",
    "        answers = {}\n",
    "        for f_key, f_value in answers_idx.items():\n",
    "            prev = 0\n",
    "            answer = {}\n",
    "            for val in f_value:\n",
    "                # print(val)\n",
    "                for s_key, s_value in val.items():\n",
    "                    # print(s_key, s_value)\n",
    "                    if s_value > prev:\n",
    "                        # print(\"True\")\n",
    "                        # print(prev)\n",
    "                        prev = s_value\n",
    "                        prev_key = s_key\n",
    "                    else:\n",
    "                        # print(\"False\")\n",
    "                        pass\n",
    "            answer[prev_key] = prev\n",
    "            answers[f_key] = answer\n",
    "\n",
    "        print(answers)\n",
    "        # print(answers_idx)\n",
    "    else:\n",
    "        answers_idx = EasyDict()\n",
    "        attr_list = [str(w) for w in id]\n",
    "\n",
    "        answers_idx[\"gender\"] = []\n",
    "        answers_idx[\"age\"] = []\n",
    "        # answers_idx[\"lowerbodylong\"] = []\n",
    "        # answers_idx[\"lowerbodyshort\"] = []\n",
    "        # answers_idx[\"lowerbodyshortskirt\"] = []\n",
    "        # answers_idx[\"lowerbodylongskirt\"] = []\n",
    "        # answers_idx[\"upperbodylongsleeve\"] = []\n",
    "        # answers_idx[\"upperbodyshortsleeve\"] = []\n",
    "        # answers_idx[\"upperbodynosleeve\"] = []\n",
    "        answers_idx[\"lowerbody\"] = []\n",
    "        answers_idx[\"upperbody\"] = []\n",
    "        answers_idx[\"hair\"] = []\n",
    "        answers_idx[\"lowercolor\"] = []\n",
    "        answers_idx[\"uppercolor\"] = []\n",
    "        answers_idx[\"haircolor\"] = []\n",
    "\n",
    "\n",
    "        for a, b in enumerate(probs):\n",
    "            list_idx = {}\n",
    "            if a in [0, 1]:\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"gender\"].append(list_idx)\n",
    "            elif a in range(2, 7):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"age\"].append(list_idx)\n",
    "\n",
    "            elif a in range(7, 11):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"lowerbody\"].append(list_idx)\n",
    "\n",
    "            elif a in range(11, 14):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"upperbody\"].append(list_idx)\n",
    "            # elif a in lowerlong:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodylong\"].append(list_idx)\n",
    "            # elif a in lowershort:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodyshort\"].append(list_idx)\n",
    "            # elif a in lowershortskirt:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodyshortskirt\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in lowerlongskirt:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"lowerbodylongskirt\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in upperlongsleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodylongsleeve\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in uppershortsleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodyshortsleeve\"].append(list_idx)\n",
    "            #\n",
    "            # elif a in uppernosleeve:\n",
    "            #     list_idx[id[a]] = b\n",
    "            #     answers_idx[\"upperbodynosleeve\"].append(list_idx)\n",
    "\n",
    "            elif a in range(14, 17):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"hair\"].append(list_idx)\n",
    "\n",
    "            elif a in range(17, 28):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"lowercolor\"].append(list_idx)\n",
    "\n",
    "            elif a in range(28, 39):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"uppercolor\"].append(list_idx)\n",
    "\n",
    "            elif a in range(39, 50):\n",
    "                list_idx[id[a]] = b\n",
    "                answers_idx[\"haircolor\"].append(list_idx)\n",
    "\n",
    "\n",
    "        answers = {}\n",
    "        for f_key, f_value in answers_idx.items():\n",
    "            prev = 0\n",
    "            answer = {}\n",
    "            for val in f_value:\n",
    "                # print(val)\n",
    "                for s_key, s_value in val.items():\n",
    "                    # print(s_key, s_value)\n",
    "                    if s_value > prev:\n",
    "                        # print(\"True\")\n",
    "                        # print(prev)\n",
    "                        prev = s_value\n",
    "                        prev_key = s_key\n",
    "                    else:\n",
    "                        # print(\"False\")\n",
    "                        pass\n",
    "            answer[prev_key] = prev\n",
    "            answers[f_key] = answer\n",
    "\n",
    "        print(answers)\n"
   ],
   "id": "198d8eab35ad72e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': {'personalMale': 0.7901217937469482}, 'age': {'personalLess30': 0.7899942994117737}, 'lowerbody': {'lowerbodylongskirt': 0.7902551293373108}, 'upperbody': {'upperbodylongsleeve': 0.790153443813324}, 'hair': {'hairBald': 0.7899038195610046}, 'lowercolor': {'lowerBodyPurple': 0.7901937365531921}, 'uppercolor': {'upperBodyOrange': 0.7900944352149963}, 'haircolor': {'hairPurple': 0.7901229858398438}}\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T05:36:41.540468Z",
     "start_time": "2025-03-06T05:36:41.538559Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7f4880d0979040bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
